{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fe24ca-0ddc-4f06-9d84-e59498bd07e5",
   "metadata": {},
   "source": [
    "## Computational Physics 2 (WS23/24) â€“ Warm-up exercise\n",
    "\n",
    "**Deadline: 31.10.2023 at 23:59**\n",
    "\n",
    "Group: *write group name*\n",
    "Students: *write names and matriculation numbers*\n",
    "\n",
    "You will implement and test two algorithms: **conjugate gradient** and **power method**. We will see in a moment what they are useful for. Fill the notebook following the instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43203cce-f800-46be-b70c-4b53fafceda0",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Here we load the needed libraries and we initialize the random number generator. **Important**: when using a random number generator, the seed needs to be set only once, preferebly at the beginning of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c0eb1-6bce-40ec-976d-f1bb77c9e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.Generator(np.random.PCG64(12345))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122e6da-eca2-4891-83f8-fb79815b7b06",
   "metadata": {},
   "source": [
    "### Positive-definite matrices\n",
    "\n",
    "Both algorithms will deal with hermitian positive-definite matrices. Recall:\n",
    "\n",
    "- Given a complex square matrix $A$, its hermitian conjugate $A^\\dagger$ is defined as its transposed complex-conjugated, i.e. $(A^\\dagger)_{ij} = (A_{ji})^*$.\n",
    "- A complex square matrix $A$ is said to be hermitian if $A=A^\\dagger$.\n",
    "- An hermitian matrix $A$ is said to be positive-definite if all its eigenvalues are positive.\n",
    "\n",
    "The following function generates and returns a random positive-definite matrix, along with its eigenvactors and eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958716e-7597-4eea-9f04-4acf920cc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function 'generate_positive_definite_matrix' contructs an NxN positive-definite matrix 'A',\n",
    "# its matrix of eigenvectors and its eigenvalues.\n",
    "#\n",
    "# Input parameters:\n",
    "#    N (integer)        : size of output matrix 'A'\n",
    "#    kappa (double)     : condition number of the output matrix 'A'\n",
    "#                         see https://en.wikipedia.org/wiki/Condition_number#Matrices\n",
    "# Output values: (A, U, evalues)\n",
    "#    A (np.matrix)      : positive-definite NxN matrix with condition number kappa\n",
    "#    U (np.matrix)      : NxN unitary matrix; each column of 'U' is an eigenvector of 'A'\n",
    "#    evalues (np.array) : N-component array with eigenvalues of 'A'\n",
    "\n",
    "def generate_positive_definite_matrix(N,kappa=10.):\n",
    "    assert isinstance(N, int) and N > 1 , \"N=\" + str(N) + \" must be an integer >= 2\"\n",
    "    assert isinstance(kappa, float) and kappa > 0. , \"kappa=\" + str(kappa) + \" must be a positive float\"\n",
    "    \n",
    "    rmat = np.asmatrix(rng.standard_normal(size=(N,N)) + 1j * rng.standard_normal(size=(N,N)))\n",
    "    U , _ = np.linalg.qr(rmat,mode='complete')\n",
    "    evalues = np.concatenate((1. + kappa*rng.random(N-2),[1.,kappa]))\n",
    "    D = np.asmatrix(np.diag(evalues))\n",
    "    A = np.matmul(np.matmul(U,D),U.getH())\n",
    "    \n",
    "    return A, U , evalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6add5b3-4910-4a78-bb3f-92a71ff95671",
   "metadata": {},
   "source": [
    "### Power method\n",
    "\n",
    "Given a positive-definite matrix $A$, the power method allows to approximate its largest eigenvalue and the corresponding eigenvector with a certain specified tolerance $\\epsilon$. It is an iterative method: a number of steps are repeated cyclically, at each iteration one gets a better approximation of the eigenvalue and eigenvectors, the iteration is stopped when the approximation is good enough. It works as follows:\n",
    "\n",
    "1. Generate a random complex vector $v$ with norm equal to 1.\n",
    "2. Calculate $w=Av$ and $\\mu = \\| w \\|$.\n",
    "3. If $\\| w - \\mu v \\| < \\epsilon$, stop iteration and returns $\\mu$ and $v$ are eigenvalue and eigenvector.\n",
    "4. Replace $v \\leftarrow \\mu^{-1} w$ and repeat from 2.\n",
    "\n",
    "**Task:** Implement the power method within the function ```power_method```, with the following specifications.\n",
    "\n",
    "The *vector* $v$ is not necessarily a one-dimensional array, we want the flexibility to use more abstract vector spaces whose elements are generic $d$-dimensional arrays. In practice, the *vectors* $v$ must be implemented as ```numpy.ndarrays```. In this setup, the squared norm $\\|v\\|^2$ of the *vector* $v$ is given by the sum of the squared absolute value of all elements of $v$. Moreover, the *matrix* $A$ really needs to be thought as a linear function acting on the elements of the abstract vector space.\n",
    "\n",
    "```power_method``` must be a function that takes three inputs:\n",
    "- ```vshape``` is the shape of the elements $v$ of the abstract vector space;\n",
    "- ```apply_A``` is a function that takes the vector $v$ (represented as an instance of ```numpy.ndarrays```) and returns the vector $Av$ (represented as an instance of ```numpy.ndarrays``` with the same shape as $v$);\n",
    "- ```epsilon``` is the tolerance.\n",
    "\n",
    "```power_method``` must return:\n",
    "- the largest eignevalue $\\mu$;\n",
    "- the corresponding eigenvector (represented as an instance of ```numpy.ndarrays``` with the same shape as the input of ```apply_A```);\n",
    "- the number of iterations.\n",
    "\n",
    "A test function is provided below. Your implementation of ```power_method``` needs to pass this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17719c-c95b-4152-bce5-0c418fb64aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function 'power_method' calculates an approximation of the largest eigenvalue 'mu'\n",
    "# and corresponding eigenvector 'v' of the positive-definite linear map 'A'. The quality\n",
    "# of the approximation is dictated by the tolerance 'epsilon', in the sense that the\n",
    "# approximated eigenvalue and eigenvector satisfy\n",
    "#   | A(v) - mu*v | < epsilon\n",
    "#\n",
    "# The vectors over which 'A' acts are generically d-dimensional arrays. More precisely,\n",
    "# they are instances of 'numpy.ndarray' with shape 'vshape'.\n",
    "#\n",
    "# The linear map 'A' is indirectly provided as a function 'apply_A' which takes a vector\n",
    "# v and returns the vector A(v).\n",
    "#\n",
    "# Input parameters of power_method:\n",
    "#    vshape (tuple of ints) : shape of the arrays over which 'A' acts\n",
    "#    apply_A (function)     : function v -> A(v)\n",
    "#    epsilon (float)        : tolerance\n",
    "# Output values: (mu, v, niters)\n",
    "#    mu (float)             : largest eigenvalue of A\n",
    "#    v (numpy.ndarray)      : corresponding eigenvector\n",
    "#    niters (int)           : number of iterations\n",
    "\n",
    "def power_method(vshape,apply_A,epsilon):\n",
    "    assert callable(apply_A) , \"apply_A must be a function\"\n",
    "    assert isinstance(epsilon, float) and epsilon > 0. , \"epsilon=\" + str(epsilon) + \" must be a positive float\"\n",
    "    assert isinstance(vshape,tuple) , \"vshape must be a tuple\"\n",
    "    \n",
    "    ### Implement your function here\n",
    "    \n",
    "    return mu, v, niters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca841b5-ff0a-4241-a225-a024406d5200",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "Run the following cell. If the power method is correctly implemented, then the test will pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d3b9a-b4de-4dc5-9c99-767c3dbb919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_power_method():\n",
    "\n",
    "    def test_engine(shape,epsilon):\n",
    "        \n",
    "        N = int(np.prod(shape))\n",
    "        A , _ , _ = generate_positive_definite_matrix(N)\n",
    "        \n",
    "        def apply_A(v):\n",
    "            assert isinstance(v,np.ndarray) , \"v must be an np.ndarray\"\n",
    "            assert v.shape==shape , \"v has shape \"+str(v.shape)+\", it must have shape \"+str(shape)\n",
    "            return np.asarray(np.dot(A,v.flatten())).reshape(shape)\n",
    "        \n",
    "        mu , v , niters = power_method(shape,apply_A,epsilon)\n",
    "        delta = apply_A(v) - mu*v\n",
    "        res = np.sqrt(np.vdot(delta,delta).real)\n",
    "        print(\"shape = \" , shape , \"\\tresidue = \" , res , \"\\titerations = \" , niters , \"\\tTest passes: \" , res<=epsilon)\n",
    "    \n",
    "    \n",
    "    test_engine((4,),1.e-8)\n",
    "    test_engine((1,5),1.e-12)\n",
    "    test_engine((3,2,4),1.e-8)\n",
    "    test_engine((5,2),1.e-12)\n",
    "\n",
    "test_power_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eac907-2458-4974-a92e-384716aa2e76",
   "metadata": {},
   "source": [
    "### Conjugate gradient\n",
    "\n",
    "**Task.**\n",
    "1. Read about the conjugate gradient on Wikipedia.\n",
    "2. Implement the conjugate gradient, using same conventions as for the power method.\n",
    "3. Write a description of the algorithm here (in the same spirit as the description of the power method).\n",
    "4. Run and pass the test provided below.\n",
    "5. Discuss intermediate steps with tutors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d2a0d-cd78-47b6-b509-fee1f8c07c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function 'conjugate_gradient' calculates an approximation 'x' of 'A^{-1}(b)', where\n",
    "# 'A' is a positive-definite linear map 'A', and 'b' is a vector in the domain of 'A'.\n",
    "# The quality of the approximation is dictated by the tolerance 'epsilon', in the sense\n",
    "# that the following inequality is satisfied\n",
    "#   | A(x) - b | <= epsilon |b|\n",
    "#\n",
    "# The vectors over which 'A' acts are generically d-dimensional arrays. More precisely,\n",
    "# they are instances of 'numpy.ndarray' with shape 'vshape'.\n",
    "#\n",
    "# The linear map 'A' is indirectly provided as a function 'apply_A' which takes a vector\n",
    "# v and returns the vector A(v).\n",
    "#\n",
    "# Input parameters of power_method:\n",
    "#    apply_A (function)     : function v -> A(v)\n",
    "#    b (numpy.ndarray)      : vector 'b'\n",
    "#    epsilon (float)        : tolerance\n",
    "# Output values: (x, niters)\n",
    "#    x (numpy.ndarray)      : approximation of 'A^{-1}(b)'\n",
    "#    niters (int)           : number of iterations\n",
    "\n",
    "def conjugate_gradient(apply_A,b,epsilon):\n",
    "\n",
    "    ### Implement your function here\n",
    "    \n",
    "    return x, niters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad99aa0-b80d-4cdb-a1a1-933b978de93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conjugate_gradient():\n",
    "\n",
    "    def test_engine(shape,epsilon):\n",
    "        \n",
    "        N = int(np.prod(shape))\n",
    "        A , _ , _ = generate_positive_definite_matrix(N)\n",
    "        b = rng.standard_normal(size=shape) + 1j * rng.standard_normal(size=shape)\n",
    "        \n",
    "        def apply_A(v):\n",
    "            assert isinstance(v,np.ndarray) , \"v must be an np.ndarray\"\n",
    "            assert v.shape==shape , \"v has shape \"+str(v.shape)+\", it must have shape \"+str(shape)\n",
    "            return np.asarray(np.dot(A,v.flatten())).reshape(shape)\n",
    "        \n",
    "        x , niters = conjugate_gradient(apply_A,b,epsilon)\n",
    "        delta = apply_A(x) - b\n",
    "        res = np.sqrt(np.vdot(delta,delta).real)\n",
    "        print(\"shape = \" , shape , \"\\tresidue = \" , res , \"\\titerations = \" , niters , \"\\tTest passes: \" , res<=epsilon*np.sqrt(np.vdot(b,b).real))\n",
    "    \n",
    "    \n",
    "    test_engine((4,),1.e-8)\n",
    "    test_engine((1,5),1.e-12)\n",
    "    test_engine((3,2,4),1.e-8)\n",
    "    test_engine((5,2),1.e-12)\n",
    "\n",
    "test_conjugate_gradient()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
